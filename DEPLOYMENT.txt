===============================================================================
CAREER PREDICTOR - COMPLETE DEPLOYMENT GUIDE
===============================================================================

SYSTEM OVERVIEW:
A statistically sound, ethically designed career prediction system with:
- 81.7% accuracy (macro-F1) on main careers
- Debiased hierarchical model (centroid + LightGBM classifier)
- Comprehensive ethical safeguards
- Bias auditing framework
- Counterfactual explanations
- Prediction monitoring

===============================================================================
WHAT WAS IMPLEMENTED:
===============================================================================

1. DATA PIPELINE:
   - Preprocessed 2,000-row dataset
   - Mapped to 12 main careers with 5 sub-tracks each
   - Balanced distribution (10.32x imbalance ratio)
   - Generated behavioral features from Q4-Q11
   - Created multi-hot skill encodings

2. ML MODELS (ml/src/):
   train.py:
   - Hierarchical LightGBM with class weighting
   - Centroid-based scoring (Academic + Behavioral)
   - Isotonic calibration
   - Anti-collapse rules (min-gap, subject sanity)
   - F1 Score: 0.817 (main), 0.542 (sub)

   service.py:
   - FastAPI on http://127.0.0.1:8001
   - Blended scoring: 50% centroid + 50% classifier
   - Bootstrap confidence intervals
   - Counterfactual explanations (how to improve for other careers)
   - Low-confidence detection

3. BACKEND INTEGRATION (backend/):
   mlbridge/featureMapping.js:
   - Converts 25Q assessment -> ML payload
   - Handles score bins, study habits, skills
   - Derives computing score from digital literacy

   mlbridge/mlClient.js:
   - HTTP bridge to ML service (5s timeout)
   - Clean error handling

   routes/ml.js:
   - POST /api/ml/predict
   - Saves predictions + logs for monitoring
   - Returns Top-N + reasons + counterfactuals

   models/PredictionLog.js:
   - Logs every prediction for monitoring
   - Tracks confidence, distribution, timestamps

4. ETHICAL SAFEGUARDS (src/pages/ResultsPage.tsx):
   - Prominent disclaimer: "This is guidance, not destiny"
   - Growth mindset messaging
   - Multiple career paths always shown
   - Counterfactual explanations
   - Link to external career resources
   - Transparency about model accuracy & biases

5. BIAS AUDITING (ml/src/bias_audit.py):
   - Analyzes prediction distribution
   - Checks confidence by career
   - Detects over/under-representation
   - Generates audit reports
   - Current status: 1 medium-severity bias (Law & Public Policy low confidence)

6. MONITORING (backend/scripts/monitor_predictions.js):
   - Tracks prediction volume & distribution
   - Confidence analysis
   - Anomaly detection
   - Automated alerts for drift

===============================================================================
HOW TO RUN:
===============================================================================

STEP 1: Preprocess Data (if needed)
cd Career_Path_project
python ml/src/preprocess_dataset.py

STEP 2: Train Models
python ml/src/train.py
Expected output: macro-F1 ~0.817

STEP 3: Start ML Service
cd ml
python -m venv env
./env/Scripts/activate  (Windows) or source env/bin/activate (Linux/Mac)
pip install -r requirements.txt
uvicorn src.service:app --host 127.0.0.1 --port 8001 --reload

STEP 4: Start Backend
cd backend
npm install
npm run start

STEP 5: Start Frontend
cd Career_Path_project
npm install
npm run dev

STEP 6: Test End-to-End
1. Navigate to http://localhost:5173 (or your Vite port)
2. Complete the 25Q assessment
3. View results with:
   - Top career + sub-track
   - Confidence indicator
   - A/B/S scores
   - Top-5 alternatives
   - Counterfactual suggestions
   - Ethical disclaimers

===============================================================================
MAINTENANCE & MONITORING:
===============================================================================

1. WEEKLY: Run bias audit
   python ml/src/bias_audit.py

2. WEEKLY: Check prediction logs
   node backend/scripts/monitor_predictions.js

3. MONTHLY: Review user feedback
   - Are predictions helpful?
   - Do users feel limited by results?
   - Any demographic patterns in complaints?

4. QUARTERLY: Retrain models
   - Gather new labeled data
   - Run preprocess_dataset.py
   - Run train.py
   - Compare F1 scores
   - Run bias audit before deploying

5. ANNUALLY: Longitudinal validation
   - Survey users who followed predictions
   - Track career satisfaction
   - Compare outcomes vs. control group

===============================================================================
ETHICAL CHECKLIST:
===============================================================================

[x] Prominent disclaimer about limitations
[x] Multiple paths always shown (Top-5)
[x] Growth mindset messaging
[x] Skills are learnable emphasis
[x] Links to external career resources
[x] Transparency about accuracy (~82%)
[x] Acknowledgment of potential biases
[x] Data privacy notice
[x] No gender/name in features
[x] Regular bias audits
[x] Prediction logging for accountability
[x] Counterfactual explanations (actionable advice)
[x] Low-confidence warnings
[x] Class balancing in training
[x] Calibrated probabilities

===============================================================================
KNOWN LIMITATIONS:
===============================================================================

1. Model trained on synthetic behavioral data (not real longitudinal outcomes)
2. No validation against actual career satisfaction
3. Dataset may not represent all demographics/regions
4. Computing score derived (not directly measured)
5. Labels based on aspirations, not outcomes
6. Law & Public Policy has lower confidence (72.7% vs 94% avg)
7. No external validation by career counselors yet

===============================================================================
FUTURE IMPROVEMENTS:
===============================================================================

1. Gather real longitudinal data (track users for 3-5 years)
2. Add user feedback loop (was prediction helpful?)
3. Implement A/B testing framework
4. Add demographic fairness metrics
5. Develop skill roadmaps (disabled button in UI)
6. Add career change predictions (people change 5-7 times)
7. Include economic factors (salary, job market demand)
8. Multi-language support
9. Mobile app
10. Partnership with career counselors for validation

===============================================================================
KEY FILES:
===============================================================================

Python ML:
- ml/src/train.py (training pipeline)
- ml/src/service.py (FastAPI scoring service)
- ml/src/preprocess_dataset.py (data transformation)
- ml/src/bias_audit.py (bias auditing)
- ml/requirements.txt (dependencies)

Backend:
- backend/routes/ml.js (prediction endpoint)
- backend/mlbridge/featureMapping.js (assessment->features)
- backend/mlbridge/mlClient.js (ML service client)
- backend/models/Prediction.js (predictions storage)
- backend/models/PredictionLog.js (monitoring logs)
- backend/scripts/monitor_predictions.js (monitoring script)

Frontend:
- src/pages/ResultsPage.tsx (results UI with ethical safeguards)
- src/components/Questionnaire.tsx (25Q assessment)
- src/index.css (animations)

Data:
- ml/data/student-scores.csv (original dataset)
- ml/data/student-scores-transformed.csv (preprocessed)
- ml/models/*.pkl (trained models)

===============================================================================
SUPPORT & TROUBLESHOOTING:
===============================================================================

ML Service won't start:
- Check Python version (3.11+)
- Verify models exist in ml/models/
- Check port 8001 not in use
- Review ml/src/service.py logs

Backend can't connect to ML:
- Verify ML service running on 127.0.0.1:8001
- Test: curl http://127.0.0.1:8001/health
- Check firewall settings

Predictions seem biased:
- Run: python ml/src/bias_audit.py
- Check prediction logs
- Review training data distribution
- Consider retraining with SMOTE

Low accuracy:
- Check dataset quality (labels correct?)
- Verify feature engineering (computing_score derivation)
- Review class imbalance (should be <10x)
- Consider ensemble methods

===============================================================================
CONTACT & CREDITS:
===============================================================================

Model: LightGBM + Centroid-based scoring
Framework: FastAPI + Express + React
Dataset: 2,000 student profiles (preprocessed)
Accuracy: 81.7% macro-F1 (main careers)
Biases: 1 medium-severity (monitored)

This system was built with ethical AI principles:
- Transparency
- Fairness
- Accountability
- Privacy
- Human oversight

Remember: This tool aids exploration, it doesn't define destiny.

===============================================================================
